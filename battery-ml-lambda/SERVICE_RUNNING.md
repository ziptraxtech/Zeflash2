# ‚úÖ ECS SERVICE IS LIVE! 

## üéØ Service Details

**Service Name**: `battery-ml-service-test`  
**Cluster**: `ml-cluster`  
**Region**: `us-east-1`  
**Status**: ‚úÖ ACTIVE & RUNNING

### üåê Service Endpoint

```
Public IP: 18.214.37.111
Port: 8000
Base URL: http://18.214.37.111:8000
```

### üîí Network Configuration

- **VPC**: `vpc-0518c5ece1e92a38d`
- **Subnets**: 
  - `subnet-066807638c2cf2357` (us-east-1b)
  - `subnet-0a92a798c960dfa84` (us-east-1a)
- **Security Group**: `sg-09f7b3f20b6dbd132`
  - Port 8000: Open to 0.0.0.0/0
  
### üì¶ Container Details

- **Task Definition**: `battery-ml-task-test:2`
- **Image**: `070872471952.dkr.ecr.us-east-1.amazonaws.com/battery-ml:test`
- **CPU**: 1024 (1 vCPU)
- **Memory**: 2048 MB (2 GB)
- **S3 Bucket**: `battery-ml-results-test`

---

## üß™ Test Your Service

### 1. Health Check (wait 1-2 min for ML models to load)

```powershell
curl http://18.214.37.111:8000/health
```

**Expected Response:**
```json
{
  "status": "healthy",
  "ml_models_loaded": true,
  "s3_bucket": "battery-ml-results-test",
  "storage_type": "s3"
}
```

### 2. API Documentation

```
http://34.205.48.128:8000/docs
```

### 3. Run Test Inference

```powershell
curl -X POST http://18.214.37.111:8000/api/v1/inference `
  -H "Content-Type: application/json" `
  -d '{\"evse_id\":\"122300103C03205\",\"connector_id\":1,\"limit\":60}'
```

**Expected Response:**
```json
{
  "job_id": "abc123...",
  "status": "processing",
  "message": "Job queued for processing"
}
```

### 4. Check Job Status

```powershell
curl http://34.205.48.128:8000/api/v1/status/<JOB_ID>
```

### 5. View Generated Images

After job completes, images are in S3:

```powershell
aws s3 ls s3://battery-ml-results-test/battery-reports/ --recursive
```

**Public URL format:**
```
https://battery-ml-results-test.s3.us-east-1.amazonaws.com/battery-reports/<job_id>.png
```

---

## üìä Monitor Your Service

### View Logs

```powershell
# Stream live logs
aws logs tail /ecs/battery-ml-test --follow --region us-east-1

# View recent logs
aws logs tail /ecs/battery-ml-test --since 10m --region us-east-1
```

### Check Service Status

```powershell
aws ecs describe-services `
  --cluster ml-cluster `
  --services battery-ml-service-test `
  --region us-east-1 `
  --query 'services[0].[serviceName,status,runningCount,desiredCount]'
```

### View Running Tasks

```powershell
aws ecs list-tasks `
  --cluster ml-cluster `
  --service battery-ml-service-test `
  --region us-east-1
```

### Get Public IP (if it changes)

```powershell
$taskArn = aws ecs list-tasks --cluster ml-cluster --service battery-ml-service-test --region us-east-1 --query 'taskArns[0]' --output text

$eniId = aws ecs describe-tasks --cluster ml-cluster --tasks $taskArn --region us-east-1 --query 'tasks[0].attachments[0].details[?name==`networkInterfaceId`].value' --output text

$publicIp = aws ec2 describe-network-interfaces --network-interface-ids $eniId --region us-east-1 --query 'NetworkInterfaces[0].Association.PublicIp' --output text

Write-Host "Public IP: $publicIp"
```

---

## üîÑ Update Your Frontend

Once you verify the service works, update your frontend to use the new API:

**In your React app** (src/services or config):

```typescript
// Change from:
const API_URL = 'http://localhost:8000'

// To:
const API_URL = 'http://18.214.37.111:8000'
```

---

## üõ†Ô∏è Manage Your Service

### Scale Service

```powershell
# Scale to 2 tasks
aws ecs update-service `
  --cluster ml-cluster `
  --service battery-ml-service-test `
  --desired-count 2 `
  --region us-east-1
```

### Update Service (after new Docker build)

```powershell
# Push new image with :test tag
docker push 070872471952.dkr.ecr.us-east-1.amazonaws.com/battery-ml:test

# Force new deployment
aws ecs update-service `
  --cluster ml-cluster `
  --service battery-ml-service-test `
  --force-new-deployment `
  --region us-east-1
```

### Stop Service (to save costs)

```powershell
# Scale to 0
aws ecs update-service `
  --cluster ml-cluster `
  --service battery-ml-service-test `
  --desired-count 0 `
  --region us-east-1
```

### Delete Service (when done testing)

```powershell
# First scale to 0
aws ecs update-service --cluster ml-cluster --service battery-ml-service-test --desired-count 0 --region us-east-1

# Wait 30 seconds

# Delete service
aws ecs delete-service --cluster ml-cluster --service battery-ml-service-test --region us-east-1

# Optional: Delete cluster
aws ecs delete-cluster --cluster ml-cluster --region us-east-1

# Optional: Delete security group
aws ec2 delete-security-group --group-id sg-09f7b3f20b6dbd132 --region us-east-1
```

---

## üí∞ Cost Breakdown

### Current Test Environment

- **ECS Fargate (1vCPU, 2GB)**: $0.04/hour = ~$29/month (24/7)
- **S3 Storage**: ~$0.023/GB/month = <$1/month
- **Data Transfer**: First 100GB free, then $0.09/GB
- **ECR Storage**: ~$0.10/GB/month = ~$0.50/month

**Total**: ~$30-35/month (if running 24/7)

### Cost Optimization

- **Scale to 0 when not in use**: $0/month when stopped
- **Use scheduled scaling**: Only run during business hours
- **Set up Application Load Balancer**: Then use multiple small tasks

---

## ‚úÖ Safety Confirmation

‚úÖ **Separate S3 bucket** - Images go to `battery-ml-results-test`  
‚úÖ **Test service name** - Won't conflict with production  
‚úÖ **Isolated cluster** - Your live website is unaffected  
‚úÖ **Test Docker tag** - Uses `:test` image

**Your live website data and services are 100% safe!**

---

## üöÄ Next Steps

1. **Wait 1-2 minutes** for ML models to load
2. **Test health endpoint**: `http://18.232.102.234:8000/health`
3. **Try API docs**: `http://18.232.102.234:8000/docs`
4. **Run test inference** with a real EVSE ID
5. **Check S3** for generated images
6. **Update frontend** to use new API URL

---

## üÜò Troubleshooting

### Service won't start
```powershell
# Check service events
aws ecs describe-services --cluster ml-cluster --services battery-ml-service-test --region us-east-1 --query 'services[0].events[0:5]'
```

### Can't access port 8000
```powershell
# Verify security group rule
aws ec2 describe-security-groups --group-ids sg-09f7b3f20b6dbd132 --region us-east-1 --query 'SecurityGroups[0].IpPermissions'
```

### High memory usage
- ML models use ~1.5GB RAM
- If tasks keep restarting, increase memory in task definition

### Slow performance
- First request loads models (~10s)
- Subsequent requests are fast (~2-5s)
- Consider keeping 1 task always running

---

**Deployment Date**: February 14, 2026  
**Status**: ‚úÖ LIVE AND READY  
**Environment**: TEST (safe for experimentation)

**Need help?** Check SAFE_DEPLOYMENT_GUIDE.md or AWS_ECS_DEPLOYMENT.md
